# 卷积原理是案例

## 一、概念

卷积神经网络（Convolutional Neural Network, CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。

卷积神经网络与普通神经网络非常相似：它们是由具有可学习权重(``weight``)和偏差(``bias``)的神经元组成的。每个神经元接收一些输入，执行一个点积，并可选择性地执行一些非线性操作，整个网络仍然可以用一系列的可微分函数表示(毕竟神经网络都是基于数学公式建立起来的)。卷积神经网络架构明确地假设输入是图像，它允许我们将某些属性编码到体系结构中，这样就可以使向前传播训练方法更高效，同时大大减少网络中的参数数量。


## 二、结构

### 2.1 常规神经网络

神经网络接收输入（例如：向量、n维矩阵），并通过一系列隐藏层进行转换。每一个隐藏的层都是由许多神经元组成的，每个神经元都与上一层神经元完全相连，而单个层中的神经元完全独立地运作，并且不共享任何连接。最后一层称为输出层，在循环神经网络中通常输出不同类别的概率。


常规的神经网络不能很好的出来图像数据。例如这里有一个32x32x3（32宽，32个高，3个颜色通道）的图片，在一个常规神经网络的第一个隐藏层中，两个神经元之间将有32*32*3=3072的权重。这个数字看起貌似还能接受，但如果换做是一个稍大像素的图片，例如200x200x3的图片，将会导致神经元有200*200*3=120000的权重。综上所述，如果给对图片大小或者神经元数量进行增加，所以这些参数数量将会疯涨！显然，这种完全的连接是浪费、可怕的，而且这种大量每个维度参数的计算会导致过拟合。


### 2.2 3D神经网络

那么为了解决以上问题，3D的神经元被引入进来。卷积神经网络假定输入数据就是图像，那么就可以专门针对这种数据结构做一些定制操作了。与常规的神经网络不同，卷积神经网络(ConvNet)的层有三个维度：宽度、高度、深度。（注意，这里的“深度”指的是激活卷的第三个维度，而是指网络中所有层的总数。）例如输入图像是激活的输入卷，并且卷的尺寸为32x32x3（分别为宽度、高度、深度）。我们很快就会看到，一层的神经元只会连接到它之前的一个小区域，而不是所有的神经元都以完全连接的方式。此外，对于cifar 10来说，最终的输出层有1x1x10维度，因为在卷积神经网络结构的末端，我们将把完整的图像压缩成一个类分数的单一向量，沿着深度维度排列。以下是可视化图片：


![](./imgs/neural_net2.jpeg)
![](./imgs/cnn.jpeg)


> 上边是正规的三层神经网络，下边是一个



***

参考链接
- [wiki-卷积神经网络](https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C#cite_note-deeplearning-1)

- [cs231n-Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)

- [卷积神经网络](https://blog.csdn.net/stdcoutzyx/article/details/41596663)
